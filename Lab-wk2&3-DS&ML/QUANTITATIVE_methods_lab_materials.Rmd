---
title: "COMP2550/COMP4450/COMP6445 - Quantitative Methods Lab Tutorial"
author: "Dr Dongwoo Kim (ANU)"
date: "18 March 2019"
output: pdf_document
---

```{r echo=FALSE}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
knitr::opts_chunk$set(error = TRUE)
```

# Introduction

In this tutorial we will be learning how to do quantitative research in a data science setting. We will be doing a small-scale project analysing Twitter data about social bots (automated accounts posing as humans) influencing public debate during the 1st U.S. Presidential Debate in 2016.

The dataset is taken from [Rizoiu et al (2018)](https://arxiv.org/abs/1802.09808)

'#DebateNight: The Role and Influence of Socialbots on Twitter During the 1st U.S. Presidential Debate' (retrieved from https://arxiv.org/abs/1802.09808)

The *assignment* in Week 4 follows on from this data set, but moves into the area of machine learning. 

Learning outcomes:

1. Import and wrangle quantitative data in the R language (a statistical programming language)
2. Basic knowledge of R programming for data science problems
3. Undertake descriptive statistical analysis of different data types
4. Plot data using graphs and label these appropriately 
5. Undertake basic inferential statistics and evaluate statistical significance

The dataset for this tutorial consists of a *random sample of 100,000* observations derived from the `#DEBATENIGHT' dataset in [Rizoiu et al (2018)](https://arxiv.org/abs/1802.09808).

## What is the #DEBATENIGHT dataset

The #DEBATENIGHT dataset contains Twitter discussions that occurred during the first 2016 U.S presidential debate between Hillary Clinton and Donald Trump. Using the Twitter Firehose API, we collected all the tweets (including retweets) that were authored during the two hour period from 8.45pm to 10.45pm EDT, on 26 September 2016, and which contain at least one of the hashtags: #DebateNight, #Debates2016, #election2016, #HillaryClinton, #Debates, #Hillary2016, #DonaldTrump and #Trump2016. 

The time range includes the 90 minutes of the presidential debate, as well as 15 minutes before and 15 minutes after the debate. The resulting dataset contains 6,498,818 tweets, emitted by 1,451,388 twitter users. For each user, the Twitter API provides aggregate information such as the number of followers, the total number (over the lifetime of the user) of emitted tweets, authored retweets, and favorites. For individual tweets, the API provides the timestamp and, if it is a retweet, the original tweet that started the retweet cascade.

## Installation of R and RStudio

This tutorial will be conducted using the R programming language. You will need to download the [R base package](https://cran.r-project.org/) and optionally [RStudio](https://www.rstudio.com/products/rstudio/download/) if you prefer a graphical user interface. Personally, I would encourage you to install RStudio as it makes project management much easier. It will also mean that you can open this tutorial RMarkdown file in RStudio and run the code directly.

Tip: Create a new *project* in RStudio where you can store your files for this project.

## Quick overview of R

In this section we will cover some basic concepts in the R language to get you up and running with it.

### 3.1 Variables

Like any programming language, you write code and execute it in the console. A difference between other languages is the assignment operator:

```{r eval=FALSE}
myVariable <- "Hello, world!"
```

What is that strange notation: `<-` ? This is known as an assignment operator. In some ways `<-` is quite similar to `=`. However, there are important differences, which is why we use the `<-` notation rather than `=`.

### Data structures and data types

#### Vectors
Probably the most important/common data structure in R are vectors. In fact, we have been already working with vectors. If you have been working through the previous examples, try typing in the following:

```{r eval=FALSE}
is.vector(myVariable)
```

In R, a vector is a set of elements that are most commonly character, logical, integer or numeric.

Here is a simple numeric vector:

```{r eval=FALSE}
x <- 5
x
```

Here is a character vector:

```{r eval=FALSE}
myName <- "John"
myName
```

We can look at attributes of vectors, e.g. finding out how many characters `myName` is. In the following code, we are using the `nchar` function and providing as input our `myName` variable.

```{r eval=FALSE}
nchar(myName)
```

We can also assign 'logical' or 'boolean' vectors, which are either TRUE or FALSE:

```{r eval=FALSE}
skyIsBlue <- TRUE
skyIsBlue
```

Then we can ask R to tell us whether `skyIsBlue` is TRUE or not, by feeding it into the `isTRUE` function:

```{r eval=FALSE}
isTRUE(skyIsBlue)
```

We don't have to have only one element in a vector. Often we want to use multiple elements, e.g. creating a numeric vector with the numbers 1 through 5.

```{r eval=FALSE}
countToFive <- c(1,2,3,4,5)
countToFive
```

We can also use shorthand notation to do the same thing:

```{r eval=FALSE}
countToTen <- 1:10
countToTen
```

We can find out how many elements are in the numeric vector:
```{r eval=FALSE}
length(countToTen)
```

We can access the fifth element of `countToTen` using the square brackets notation. This indexes `countToTen` and looks for the fifth element, and returns the value to us.

```{r eval=FALSE}
countToTen[5]
```

We can also access the first 3 elements:
```{r eval=FALSE}
countToTen[1:3]
```

We can find out information about our `countToTen` vector. The `typeof` function gives us basic information about the type of object. The `str` function is useful for finding out more detail what an object is. This tells us that it is of type 'int' (integer).

```{r eval=FALSE}
typeof(countToTen)
str(countToTen)
```

We can also examine the `myName` character vector that we created earlier. Note the difference, namely that is of type 'chr' (character).

```{r eval=FALSE}
str(myName)
```

#### Matrices

Matrices are special vectors in R. They are 'atomic', so they can only contain data of one type (e.g. you can't have a column with integer data and another column with character data).

Matrices are filled column-wise, for example:

```{r eval=FALSE}
myMatrix <- matrix(1:6, nrow = 2, ncol = 3)
myMatrix
```

You can make a matrix out of two vector objects, for example:

```{r eval=FALSE}
vector1 <- 1:5
vector2 <- 6:10
myMatrix2 <- cbind(vector1,vector2)
myMatrix2
```

There are some new things here. We defined two numeric vectors `vector1` and `vector2`. Then we used the `cbind` function to 'stick' these together column-wise (i.e. vertically next to each other). The result is stored in a new variable called `myMatrix2`, which is a matrix, because it is a multi-dimensional numeric vector. The matrix also has names for the columns, which it gets automatically from the names of the variables `vector1` and `vector2`.

We can access the column names of myMatrix2:

```{r eval=FALSE}
colnames(myMatrix2)
```

We access the element in the first row and second column using the square bracket notation for accessing particular elements (i.e. fishing out the values of particular cells of the matrix). Within the square brackets we have the row number on the left hand side of the comma, and the column number of the right hand side of the comma. For example, if we want to access the value of the cell in the first row and second column we would use:

```{r eval=FALSE}
myMatrix2[1,2]
```

We can access all of the second column of our matrix by simply not providing a row number (i.e. leaving it empty on the left hand side of the comma):

```{r eval=FALSE}
myMatrix2[,2]
```

#### Lists

Lists in R are fairly similar to other languages. They can contain elements of different types (unlike vectors and matrices).

```{r eval=FALSE}
myList <- list("Hello", 1, TRUE, "Goodbye")
myList
```

We access elements in lists slightly differently to vectors, but still use the square brackets notation.

```{r eval=FALSE}
myList[1]
```

We are accessing the first 'slice' of `myList`, which is a list which itself also contains one element, namely the character vector "Hello". The list contains nested elements.

We can get more specific and access the "Hello" element, using double square brackets notation. The next line of code accesses the first slice of `myList`, accessed using the subset `[1]`, and then the first element within that slice, accessed using the subset `[[1]]`. We are subsetting `myList` twice, once with `[1]` and secondly with `[[1]]`.

```{r eval=FALSE}
myList[[1]][1]
```

Similarly, we access the first element of the *second* slice of `myList` like this:

```{r eval=FALSE}
myList[[2]][1]
```

#### Factors

In R, factors are special vectors that represent categorical data.

Here we create a factor `myFactor` that provides data on 5 students and whether each one passed or failed their assignments. We can see that there are two 'levels' to this factor, namely "pass" or "fail". (This is a very badly performing sample of students!)

```{r eval=FALSE}
myFactor <- factor(c("pass", "fail", "fail", "pass", "fail"))
myFactor
```

We can subset the factor to find which students are "fail". This returns the indexes of the elements in `myFactor` that equal "fail". Notice that the equals sign is `==` (not `=`). This double equals sign is used to test for equality. Here we are asking the question: which elements of `myFactor` are equal to "fail"? If there are any elements that match, then it returns the indexes of these elements. Sure as eggs, they match up with what we expect (the 2nd, 3rd, and 5th elements are fail).

```{r eval=FALSE}
which(myFactor=="fail")
```

#### 3.3.5 Data frames

Data frames are very important in R, and we will use them a lot.

Data frames are similar to matrices, in that they are often two-dimensional with rows and columns. Roughly speaking, the biggest difference between data frames and matrices is that data frames can contain columns *with different types of data*.

In this way, each column in the data frame can have a different data type, for example:

```{r eval=FALSE}
df <- data.frame(names = c("John","Jane","Sally"), 
  testScores=c(99,84,30), failingGrade=c(FALSE, FALSE, TRUE))
df
```

We can access the data in the third column in two ways. First, we can use the brackets notation:

```{r eval=FALSE}
df[,3]
```

We can also use the dollar sign notation to do the same thing. We know that the third column of `df` has name, 'failingGrade', so we can subset the data frame by name using the dollar sign notation:

```{r eval=FALSE}
df$failingGrade
```

We can find the number of rows in data frame by calling the `nrow` function and supplying `df` as input to it:

```{r eval=FALSE}
nrow(df)
```

We can also find out the structure of each column of `df` using the `str` function:

```{r eval=FALSE}
str(df)
```

Finally, we can view the data frame quite nicely using the `View` function. This is especially useful for working with large data frames that we will be working with in the remainder of this tutorial.

```{r eval=FALSE}
View(df)
```

## Loading and wrangling the #DEBATENIGHT dataset

Now that you are familiar with R syntax we will import the dataset and start analysing it.

Download the dataset and save it to your local working directory in R. The dataset can be downloaded from: http://128.199.169.209/sample_users_100k.csv.bz2 .

```{r}
data_df <- read.csv("sample_users_100k.csv",sep="\t",stringsAsFactors = F)
```

We also want to install an external R package called `Rmisc`. The Rmisc library contains many functions useful for data analysis and utility operations.

```{r}
# install.packages("Rmisc")
library(Rmisc)
```

We will find out some information about our data:

```{r}
str(data_df)
```

We can view the dataframe with the following command. It is useful to have this open so you can refer to it.

```{r}
View(data_df)
```

A super useful function in R is `summary()`, which takes care of many descriptive statistics of interest for each variable:

```{r}
summary(data_df)
```

The `summarySE` function in the `Rmisc` package outputs the number of observations, mean, standard deviation, standard error of the mean, and confidence interval for grouped data.  The summarySE function allows you to summarize over the combination of multiple independent variables by listing them as a vector, e.g. c("friendsCount", "followersCount").

First we will coerce the `verified` variable to a factor and use the `table` function to look at the distribution.

```{r}
data_df$verified <- as.factor(data_df$verified)
table(data_df$verified)
```

Then we call the `summarySE` function to look at how the number of followers of users (followersCount) varies depending on whether the user is 'verified' or not (has established their true identity with Twitter). Obviously, celebrities and public figures will be more likely to verify themselves, so we can see that the followers numbers are much higher for verified users.

At the same time, we see that standard error (SE) and confidence intervals (CI) are also higher for the sample of verified users. 

Remember when it comes to standard error and confidence interval, smaller is better: smaller values mean the more representative the sample will be of the overall population.

```{r}
summarySE(data=data_df,
          "followersCount",
          groupvars="verified",
          conf.interval = 0.95, na.rm = T)
```

One of the variables we are particularly interested in is the `botscore`. Obviously, there is an issue with the summary statistics for this variable, because it should be numeric and the range should be 0 to 1. 

```{r}
summary(data_df$botscore)
```

As you can see, running the summary doesn't tell us much! We can see that the structure of this variable is of type `character`, and there are some clearly non-numeric values.

```{r}
str(data_df$botscore)
```

So, let's wrangle this variable and fix it up. First, we will coerce it from character to numeric. Note the warning from R telling us that it had to introduce `NA` values. These `NA` values denote missing data and were previously the elements that were not numeric (e.g. 'deleted', 'suspended').

```{r}
data_df$botscore <- as.numeric(data_df$botscore)
```

When we re-run summary, we also notice that range has a problem with some erroneous data creeping (probably due to the coercion), with values of minus infinity (!) which R understands as `-Inf`. Let's fix that too.

```{r}
toDel <- which(data_df$botscore < 0)
data_df <- data_df[-toDel,]
```

Now we have our correct bot scores:

```{r}
summary(data_df$botscore)
```
```{r}
plot(sort(data_df$botscore),main="Distribution of bot scores by users",
        ylab = "Bot score", xlab = "# User")
```

A more instructive view of the bot scores can be gained through box plots:

```{r}
boxplot(data_df$botscore,main="Boxplot of bot score data",ylab="Bot score")
```

You can see there are many scores that are determined as outliers. In order to be an outlier, the data value must be:

- larger than Q3 by at least 1.5 times the interquartile range (IQR), or
- smaller than Q1 by at least 1.5 times the IQR.

Remember that the IQR = Q3 minus Q1.

Another way to view the bot score data is using a histogram:

```{r}
hist(data_df$botscore,main="Bot score histogram")
```

A simple tweak to the function call lets you estimate and visualise a density plot:

```{r}
densityVal <- density(data_df$botscore,na.rm = T)
plot(densityVal,type="n", main="Density plot of bot scores")
polygon(densityVal, col="red", border="gray")
```

## Inferential statistics

In the lecture we learned about inferential statistics. When trying to determine whether two variables are related (e.g., class attendance and assignment grades), statistical testing of hypotheses is the tool most frequently used. To test this, two types of hypotheses are considered, the research or alternative hypothesis and the null hypothesis.

In this section we will do some statistical tests to look at relationships between variables in the dataset.

Although we could use a variety of tests, in this lab we will focus on using the t-test (as described in the lecture). 

### T-test example

Suppose that we wish to find out whether there is a statistically significant difference between the mean of the ratio of friends (`friendsCount`) to followers (`followersCount`) of *humans* VS *bots*. Let's call this ratio $psi$. 

Our intuition is that bots will follow other users but not attract as many followers back, whereas humans will tend to have a greater reciprocity of social ties. The $psi$ metric is a crude way to measure this.  

Our research hypothesis might something like:

**Ha: Bots will have a higher friends/followers ratio than humans.**

The null hypothesis therefore:

**Ho: There is no significant difference in $psi$ between humans and bots.**

First we calculate the ratio $psi$ and store it in the dataframe. To avoid a situation of dividing by zero, we make a small adjustment to the formula. 

```{r}
data_df$friendsFollowersRatio <- data_df$friendsCount / (data_df$followersCount + 0.01)
```

Let's now examine the means of the bot group versus the human group. We will use a very simple threshold. If the score is less than or equal to 0.5, then *human*; otherwise *bot*. 

```{r}
# Human mean friend/follower ratio:
mean(data_df$friendsFollowersRatio[data_df$botscore <= 0.5],na.rm = T)

# Bot mean friend/follower ratio:
mean(data_df$friendsFollowersRatio[data_df$botscore > 0.5],na.rm = T)
```

This suggests that bots have a much more positively skewed $psi$ ratio. But how can we be sure it's not due to chance? We use the t-test. 

We want to specify a one-sided t-test because we want to establish not simply whether there is *any* significant relationship between $psi$ and bot score but also the direction of the relationship. We are hypothesising that when the friends/followers ratio $psi$ is high, the bot score is also high. The parameter of the `t.test()` function for specifying this one-sided test is the `alternative` parameter, and we pass the "greater" argument to it. 

```{r}
t.test(data_df$friendsFollowersRatio[data_df$botscore <= 0.5],data_df$friendsFollowersRatio[data_df$botscore > 0.5],alternative = "less")
```

From these results we can see that `t` (the t-ratio) is quite large and `p` (the p-value) is very small and much lower than < 0.001. **This is a significant result!**. Therefore, we can reject the null hypothesis and accept the research or alternative hypothesis, thus concluding that bots are more likely to have a higher $psi$.

Additionally: the null hypothesis is that the mean of $psi$ for bots is 6.492005. The alternate hypothesis is that the data come from a distribution with mean greater than 6.492005. 

The test rejected the null hypothesis, and the 95% confidence interval is that the mean is greater than 6.492005, which equivalent to saying it is in the interval [8.736995,Inf].

## Data exploration and analysis

For the remainder of this lab session I encourage you to play around with the dataset, and to try out different things with it. You may wish to:

- wrangle or clean variables in order to use them in analysis
- calculate some distributions and do some plots (e.g. histograms and boxplots)
- do some statistical tests between variables and see whether you can come up with significant p-values!

Have a look at the following webpage for a list of statistical tests you can experiment with in R: http://r-statistics.co/Statistical-Tests-in-R.html .

The machine learning course next week will focus on linear regression, which follows on naturally from what you have learned here. You will move into the area of *prediction* in the next lecture and lab. You can get a head start on the assignment by learning about and describing your data and testing some of the relationships in it! 

## Conclusion

Thanks for attending today. If you have any questions please contact me (Dongwoo.Kim@anu.edu.au).

Dongwoo
