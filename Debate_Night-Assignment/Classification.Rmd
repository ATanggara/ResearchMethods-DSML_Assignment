---
title: "Debate Night Classification"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.


### Create classification Target

Create $isbot \;\in \{0,1\}$ column based on botscore
```{r}
dataset$isbot <- F
suspended <- which(dataset$botscore == "suspended")
dataset$isbot[suspended] = T
protected <- which(dataset$botscore == "protected")
dataset$isbot[protected] = F
dataset$isbot <- factor(dataset$isbot)

botrows <- which(dataset$botscore > 0.5)
dataset$isbot[botrows] = T

# remove "botscore" column
dataset$botscore <- NULL

summary(dataset)
str(dataset)
```

Some plots
```{r}
# plot(dataset$influence, dataset$isbot)
# plot(dataset$mcsize, dataset$isbot)
# plot(dataset$verified, dataset$isbot)
# plot(dataset$tweetsCount, dataset$isbot)
# plot(dataset)
```


### Preprocess data with PCA
```{r}
# separate features and target
target <- dataset$isbot
features <- dataset
features$isbot <- NULL

pca <- preProcess(features, method = c("center", "scale", "pca"),
                  thresh = 0.95, pcaComp = NULL)
print(pca)
pca_transformed <- predict(pca, dataset)

summary(pca_transformed)
```

### Normalize by sandardizing (0 mean and 1 stdev)

normalize PCA transformed features
```{r}
# separate features and target
target <- dataset$isbot
features <- dataset
features$isbot <- NULL

normalized <- normalize(features, method = "standardize", range = c(0, 1), 
                             on.constant = "quiet")

# put together processed feature columns and target
normalized <- cbind(target, normalized)

# rename target variable
colnames(normalized)[1] <- "isbot"

summary(normalized)
```


### normalized (scaled) dataset
```{r}
# separate features and target
ntarget <- data.frame(dataset$isbot)
nfeatures <- dataset

# catdata <- as.factor(cbind(dataset$verified, dataset$location.objectType))

#remove categorial and target data
nfeatures$isbot <- NULL
nfeatures$verified <- NULL
nfeatures$location.objectType <- NULL

# scale features to mean=0 and stdev=1
normalized <- scale(nfeatures)

normalized <- cbind(ntarget,normalized, dataset$verified, dataset$location.objectType)
# normalized <- data.frame(normalized)
colnames(normalized)[1] <- "isbot"
colnames(normalized)[12] <- "location.objectType"
colnames(normalized)[11] <- "verified"

summary(normalized)
```


Splitting Training set and Test set:
determine source of preprocessing
```{r}
data <- normalized
split_point <- 0.75*nrow(data)
data_train <- data[1:split_point,]
data_test <- data[(split_point+1):nrow(data),]
```


### Dataset Balancing

```{r}
library(ROSE)
library(rpart)
```

```{r}
table(data_train$isbot)
treeimb <- rpart(isbot ~ ., data = data_train)
treeimb
pred_treeimb <- predict(treeimb, newdata = data_test, threshold = 0.1)
accuracy.meas(data_test$isbot, pred.treeimb[,2])
```

```{r}
data_balanced_over <- ovun.sample(isbot ~ ., data = data_train, method = "over",N = 70000)$data
table(data_balanced_over$cls)
```


### Penalized SVM

```{r}
library(penalizedSVM)
```


### Decision Tree

```{r}
library(rpart)
```

```{r}

# control
treecon <- rpart.control(minsplit = 120,
                         minbucket = 5,
                         cp = 0.00000001,
                         xval = 25,
                         maxdepth = 10)

# grow tree 
fit <- rpart(isbot ~ .,
   method = "class", data = data_train,
   parms = list( loss = matrix(c(0,7,1,0)), split = "gini" ),
   control = treecon)

printcp(fit) # display the results 
plotcp(fit) # visualize cross-validation results 
summary(fit) # detailed summary of splits

# plot tree 
# plot(fit, uniform=TRUE,
#    main="Classification Tree")
# text(fit, use.n=TRUE, all=TRUE, cex=.8)

```

Prediction before pruning
```{r}
tree_pred <- predict(fit, data_test,
                     type = "class")
  
pred_obs <- data.frame(predicted = tree_pred, observed = data_test$isbot)
confusionMatrix(data = tree_pred, reference = data_test$isbot, 
                dnn = c("Predicted", "Observed"), positive = "TRUE", mode = "everything")
```

Tree Pruning
```{r}
# prune the tree 
pfit <- prune(fit,
              cp=0.00005)

# plot the pruned tree 
plot(pfit, uniform=TRUE,
   main="Pruned Classification Tree")
text(pfit, use.n=TRUE, all=TRUE, cex=.8)
```

Prediction after pruning
```{r}
tree_pred <- predict(pfit, data_test,
                     type = "class")
  
pred_obs <- data.frame(predicted = tree_pred, observed = data_test$isbot)
confusionMatrix(data = tree_pred, reference = data_test$isbot, 
                dnn = c("Predicted", "Observed"), positive = "TRUE", mode = "everything")
```


### Random Forest

```{r}
modFit <- train(isbot ~ . , data=data_train, method="rf", prox=TRUE)
```


```{r}
library(ISLR)
```


### Logistic regression + Cost-sensitive

```{r}
library(glmnet)
```

Preprocess Train and Test data
```{r}
y <- data_train$isbot
y <- as.numeric(y)
y <- y-1

x <- data_train
x$isbot <- NULL
x <- as.matrix(x)

test <- data_test
test$isbot <- as.numeric(test$isbot)
test$isbot <- test$isbot - 1
```

#### Train model
```{r}
glmnet <- glmnet(x=x, y=y, family="binomial")
plot(glmnet)
```

```{r}
glmnet_pred <- predict(
  glmnet,
  newx = test,
  s = "lambda.1se",
  type = "response"
)

result_df <- data.frame(
  threshold = seq(from = 0.00, to = 1.0, by = 0.01),
  expected_cost = rep(0, 101)
)

i <- 0

for(threshold in seq(from = 0.00, to = 1.0, by = 0.01)){

  i <- i + 1

  prediction_v <- 1 + as.numeric(cv.glmnet_prediction_v >= threshold)
  match_count <- sum(prediction_v == actual_v)
  true_positive_count <- sum(
    prediction_v * actual_v == 1
  )
  true_negative_count <- sum(
    prediction_v * actual_v == 4
  )
  false_positive_count <- sum(prediction_v < actual_v)
  false_negative_count <- sum(prediction_v > actual_v)
  total_cost <-
    false_positive_cost * false_positive_count +
    false_negative_cost * false_negative_count
  expected_cost <- total_cost / nrow(GermanCredit)
  result_df$expected_cost[i] <- expected_cost
}

result_df[which(result_df$expected_cost == min(result_df$expected_cost)), ]
```


#### Train model with cross validation
```{r}
glmnet_cv <- cv.glmnet(x=x, y=y, type.measure="auc")
plot(glmnet_cv)
```


```{r}
GermanCredit <- dataset

false_positive_cost <- 5

false_negative_cost <- 100

x <- GermanCredit

x$Class <- NULL

x <- as.matrix(x)

y <- as.numeric(GermanCredit$Class)

cv.glmnet_model <- cv.glmnet(
  x = x,
  y = y,
  family = "binomial"
)

cv.glmnet_prediction_v <- predict(

  cv.glmnet_model,

  newx = x,

  s = "lambda.1se",

  type = "response"

)

result_df <- data.frame(

  threshold = seq(from = 0.00, to = 1.0, by = 0.01),

  expected_cost = rep(0, 101)

)

i <- 0

for(threshold in seq(from = 0.00, to = 1.0, by = 0.01)){

  i <- i + 1

  prediction_v <- 1 + as.numeric(cv.glmnet_prediction_v >= threshold)

  match_count <- sum(prediction_v == actual_v)

  true_positive_count <- sum(

    prediction_v * actual_v == 1

  )

  true_negative_count <- sum(

    prediction_v * actual_v == 4

  )

  false_positive_count <- sum(prediction_v < actual_v)

  false_negative_count <- sum(prediction_v > actual_v)

  total_cost <-

    false_positive_cost * false_positive_count +

    false_negative_cost * false_negative_count

  expected_cost <- total_cost / nrow(GermanCredit)

  result_df$expected_cost[i] <- expected_cost

}

result_df[which(result_df$expected_cost == min(result_df$expected_cost)), ]
```


### KNN Classifier

```{r}
library(class)
library(DMwR)
```


Preprocessing
```{r}
knn_data <- normalized

knn_data$verified <- NULL
knn_data$location.objectType <- NULL

split_point <- 0.75*nrow(knn_data)
knn_train <- knn_data[1:split_point,]
knn_test <- knn_data[(split_point+1):nrow(knn_data),]

# knn_data$isbot <- NULL


summary(knn_train)
```


```{r}
repeats = 3
numbers = 10
tunel = 10

set.seed(1234)
knn_control = trainControl(method = "repeatedcv",
                 number = numbers,
                 repeats = repeats,
                 classProbs = TRUE,
                 summaryFunction = twoClassSummary)
```

```{r}
# knn <- train(isbot ~ ., data = knn_train, method = "knn",
#                preProcess = c("center","scale"),
#                trControl = x,
#                metric = "ROC",
#                tuneLength = tunel)
# 
# # Summary of model
# knn
# plot(knn)
```

```{r}
knn <- kNN(isbot ~ ., train=knn_train, test=knn_test,
           k=10)

##create confusion matrix
tab <- table(knn, knn_test$isbot)
tab
```


### Logistic Regression Classifier

construct trainControl object
```{r}
train_control <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 10,
  returnResamp = "all"
)
```

contruct Logistic Regression Classifier
```{r}
model_logistic <- train(isbot ~ ., data = data_train, 
                        method = "glm", family="binomial",
                        trControl = train_control)
model_logistic
```



Testing Classifier on the Test Set
```{r}
model_logistic_pred <- predict(model_logistic, data_test, type="raw")
postResample(pred = model_logistic_pred, obs = data_test$isbot)
```

Logistic Regression Confusion Matrix
```{r}
pred_obs <- data.frame(predicted = model_logistic_pred, observed = data_test$isbot)
confusionMatrix(data = model_logistic_pred, reference = data_test$isbot, 
                dnn = c("Predicted", "Observed"), positive = "TRUE", mode = "everything")
```


### SVM Classifier

#### SVM w/ Polynomial Kernel
```{r}
reg_const = 2

svmsig <- svm(isbot ~ ., data = data_train, 
              kernel = "polynomial", 
              gamma = 0.05,
              cost = reg_const, 
              scale = FALSE)
svmsig
```

Testing Sigmoid SVM on Training set
```{r}
svmsigmoid_trainpred <- predict(svmsig, data_train, type="raw")
postResample(pred = svmsigmoid_trainpred, obs = data_train$isbot)
```

```{r}
svmsig_pred_obs <- data.frame(predicted = svmsigmoid_trainpred, observed = data_train$isbot)
confusionMatrix(data = svmsigmoid_trainpred, reference = data_train$isbot, 
                dnn = c("Predicted", "Observed"), positive = "TRUE", mode = "everything")
```


Testing Sigmoid SVM on the Test Set
```{r}
svmsigmoid_testpred <- predict(svmsig, data_test, type="raw")
postResample(pred = svmsigmoid_testpred, obs = data_test$isbot)
```

Sigmoid SVM Confusion Matrix
```{r}
svmsig_pred_obs <- data.frame(predicted = svmsigmoid_testpred, observed = data_test$isbot)
confusionMatrix(data = svmsigmoid_testpred, reference = data_test$isbot, 
                dnn = c("Predicted", "Observed"), positive = "TRUE", mode = "everything")
```


#### SVM w/ Radial Kernel
```{r}
reg_const = 1
svmrad <- svm(isbot ~ ., data = data_train, 
               kernel = "radial",
               cost = reg_const,
               scale = FALSE)
svmrad
```

Testing Sigmoid SVM on the Training Set
```{r}
svmrad_trainpred <- predict(svmrad, data_train, type="raw")
postResample(pred = svmrad_trainpred, obs = data_train$isbot)
```

Testing Sigmoid SVM on the Test Set
```{r}
svmrad_testpred <- predict(svmrad, data_test, type="raw")
postResample(pred = svmrad_testpred, obs = data_test$isbot)
```

Sigmoid SVM Confusion Matrix
```{r}
pred_obs <- data.frame(predicted = svmrad_testpred, observed = data_test$isbot)
confusionMatrix(data = svmrad_testpred, reference = data_test$isbot, 
                dnn = c("Predicted", "Observed"), positive = "TRUE", mode = "everything")
```

#### SVM w/ Radial Kernel - Larger regularization multiplier
```{r}
reg_mult = 15

svmrad_lg <- svm(isbot ~ ., data = data_train, 
               kernel = "radial", 
               cost = reg_mult, 
               scale = FALSE)
svmrad_lg
```

Testing Sigmoid SVM on the Training Set
```{r}
svmradlg_trainpred <- predict(svmrad_lg, data_train, type="raw")
postResample(pred = svmradlg_trainpred, obs = data_train$isbot)
```

Testing Sigmoid SVM on the Test Set
```{r}
svmradlg_testpred <- predict(svmrad_lg, data_test, type="raw")
postResample(pred = svmradlg_testpred, obs = data_test$isbot)
```

Sigmoid SVM Confusion Matrix
```{r}
pred_obs <- data.frame(predicted = svmradlg_testpred, observed = data_test$isbot)
confusionMatrix(data = svmradlg_testpred, reference = data_test$isbot, 
                dnn = c("Predicted", "Observed"), positive = "TRUE", mode = "everything")
```


#### Visualize SVM classifier
```{r}
plot(svmrad_lg, data_train, listedCount ~ followersCount,
     xlim=c(0,1500), ylim=c(0,50000))
```


### Implement Artificial Neural Network

Load library
```{r}
library(neuralnet)
```

Train Neural net
```{r}
layer_neurons = c(3,2)

n <- names(data_train)

nn = neuralnet(isbot ~ ., data = data_train, hidden = layer_neurons, 
               threshold = 0.0005,act.fct = "logistic", 
               linear.output = T, algorithm = "rprop+", learningrate = )
```


### Construct a KNN Classifier



